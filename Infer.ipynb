{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os.path\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import torch\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.multiprocessing.set_start_method('spawn')\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from network.net import UNet3D\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "import sys\n",
    "assert sys.version_info.major == 3, 'Not running on Python 3'\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img_path = \"/home/imag2/IMAG2_DL/KDCompression/Dataset/KING.nii.gz\"\n",
    "model_path = \"trained_models/Vessels/KD.pt\"\n",
    "\n",
    "\n",
    "patch_size = np.array([96, 48, 96])\n",
    "half_size = patch_size // 2\n",
    "out_path = \"test.nii.gz\"\n",
    "threshold = 0.2\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = UNet3D()\n",
    "model.to(device, non_blocking=True)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img, patch_size):\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    if std > 0:\n",
    "        img = (img - mean) / std\n",
    "    else:\n",
    "        img *= 0.\n",
    "\n",
    "    if np.any(img.shape < patch_size):\n",
    "        to_pad = np.maximum(patch_size - img.shape, np.zeros(3)).astype(np.int16)\n",
    "        img = np.pad(img,\n",
    "                     ((to_pad[0] // 2, to_pad[0] - to_pad[0] // 2),\n",
    "                      (to_pad[1] // 2, to_pad[1] - to_pad[1] // 2),\n",
    "                      (to_pad[2] // 2, to_pad[2] - to_pad[2] // 2)),\n",
    "                     mode='constant', constant_values=0)\n",
    "\n",
    "    return img\n",
    "\n",
    "def load_img(f_name, patch_size, is_mask=False):\n",
    "    img = nib.load(f_name)\n",
    "    img = nib.as_closest_canonical(img)\n",
    "    affine = img.affine\n",
    "    img = img.get_fdata().astype(np.float32)\n",
    "\n",
    "    return preprocess_img(img, patch_size), affine\n",
    "\n",
    "\n",
    "def save_seg(f_name, segmentation, affine, dtype=np.uint8):\n",
    "    segmentation = nib.Nifti1Image(segmentation.astype(dtype), affine)\n",
    "    nib.save(segmentation, f_name)\n",
    "\n",
    "\n",
    "def get_grid(img, patch_size):\n",
    "    x = np.linspace(half_size[0], img.shape[0] - half_size[0], 2 * img.shape[0] // patch_size[0] + 1)\n",
    "    y = np.linspace(half_size[1], img.shape[1] - half_size[1], 2 * img.shape[1] // patch_size[1] + 1)\n",
    "    z = np.linspace(half_size[2], img.shape[2] - half_size[2], 2 * img.shape[2] // patch_size[2] + 1)\n",
    "    return x, y, z\n",
    "\n",
    "def _get_merge_fn(size, fn='flat', t=0.2):\n",
    "    if fn == 'flat':\n",
    "        return np.ones(size)\n",
    "    elif fn == 'dt':\n",
    "        _merge_fn = np.zeros(size)\n",
    "        _merge_fn = np.sqrt(((np.argwhere(_merge_fn == 0) - size // 2) ** 2).sum(axis=1)).reshape(size)\n",
    "        return np.maximum(1 - _merge_fn / np.amax(_merge_fn), t)\n",
    "    elif fn == 'borders':\n",
    "        _merge_fn = np.ones(size)\n",
    "        _merge_fn = np.pad(_merge_fn, ((1, 1), (1, 1), (1, 1)))\n",
    "        _merge_fn = distance_transform_edt(_merge_fn)\n",
    "        _merge_fn = _merge_fn[1:-1, 1:-1, 1:-1]\n",
    "        return np.maximum(_merge_fn / np.amax(_merge_fn), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img, img_affine = load_img(img_path, patch_size)\n",
    "\n",
    "grid = get_grid(img, patch_size)\n",
    "merge_fn = _get_merge_fn(patch_size, fn='borders', t=0.)\n",
    "\n",
    "x, y, z = grid\n",
    "seg = np.zeros([img.shape[0], img.shape[1], img.shape[2]])\n",
    "weights = np.zeros([img.shape[0], img.shape[1], img.shape[2]])\n",
    "for ind in np.array(np.meshgrid(x, y, z)).T.reshape(-1, 3).astype(np.int16):\n",
    "    x_min, y_min, z_min = ind - half_size\n",
    "    x_max, y_max, z_max = ind + half_size\n",
    "\n",
    "    current_patch = img[x_min:x_max, y_min:y_max, z_min:z_max]\n",
    "    current_seg = seg[x_min:x_max, y_min:y_max, z_min:z_max]\n",
    "    current_weights = weights[x_min:x_max, y_min:y_max, z_min:z_max]\n",
    "    \n",
    "    current_patch = np.expand_dims(current_patch.transpose((2, 0, 1)), axis=0)\n",
    "    current_patch = torch.from_numpy(np.expand_dims(current_patch, axis=0))\n",
    "\n",
    "    prediction = np.squeeze(torch.sigmoid(model(current_patch.to(device, non_blocking=True))).cpu().detach().numpy()).transpose((1,2,0))\n",
    "    prediction = (current_seg * current_weights + prediction * merge_fn) / (current_weights + merge_fn)\n",
    "\n",
    "    seg[x_min:x_max, y_min:y_max, z_min:z_max] = prediction\n",
    "    weights[x_min:x_max, y_min:y_max, z_min:z_max] = current_weights + merge_fn\n",
    "    \n",
    "save_seg(out_path, seg > threshold, img_affine) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
